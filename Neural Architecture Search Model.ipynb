{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d587a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#running on Python 3.8.12\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import autokeras as ak\n",
    "import statistics as stat\n",
    "import random as rand\n",
    "import keras_tuner as kt\n",
    "\n",
    "from numpy import asarray, hstack, array\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM\n",
    "from tensorflow.keras.models import Sequential, clone_model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.metrics import RootMeanSquaredError\n",
    "from tensorflow.keras.metrics import MeanAbsoluteError\n",
    "from tensorflow.keras.metrics import MeanAbsolutePercentageError\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "\n",
    "from pandas import Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cdae21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get dataset\n",
    "src = r'.\\data\\ncr_may72022.csv'\n",
    "dataset = pd.read_csv(src)\n",
    "dataset = dataset.drop(0)\n",
    "actual = pd.read_csv(r'.\\data\\ncr_may72022_casesonly.csv')\n",
    "actual['Date'] = pd.to_datetime(actual['Date'],format = '%m/%d/%Y')\n",
    "\n",
    "def reshape(series):\n",
    "    series = series.reshape((len(series),1))\n",
    "    return series\n",
    "\n",
    "def scale(series):\n",
    "    scaler = MinMaxScaler(feature_range = (0,1))\n",
    "    series = scaler.fit_transform(series)\n",
    "    return series\n",
    "\n",
    "def split_sequences(sequences, n_steps_in, n_steps_out):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        seq_x, seq_y = sequences[i:end_ix, :-1],sequences[end_ix-1:out_end_ix, -1]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y)\n",
    "    return array(X), array(y)\n",
    "\n",
    "def split_y(sequences, n_steps_in, n_steps_out):\n",
    "    y = list()\n",
    "    for i in range(len(sequences)):\n",
    "        end_ix = i + n_steps_in\n",
    "        out_end_ix = end_ix + n_steps_out-1\n",
    "        if out_end_ix > len(sequences):\n",
    "            break\n",
    "        seq_y = sequences[end_ix-1:out_end_ix, -1]\n",
    "        y.append(seq_y)\n",
    "    return array(y)\n",
    "        \n",
    "def akTSFModel(seed, lookback):\n",
    "    clf = ak.TimeseriesForecaster(\n",
    "        lookback=lookback,\n",
    "        max_trials=10,\n",
    "        metrics=[tf.keras.metrics.RootMeanSquaredError(), tf.keras.metrics.MeanAbsoluteError(), tf.keras.metrics.MeanAbsolutePercentageError()],\n",
    "        overwrite = True,\n",
    "        loss = 'mse',\n",
    "        seed = seed,\n",
    "    )\n",
    "    return clf\n",
    "\n",
    "def plot(predictions, actual, i):\n",
    "    plt.plot(actual, color = 'green')\n",
    "    plt.plot(predictions, color = 'red')\n",
    "    plt.title('Risk Model vs Actual')\n",
    "    plt.legend(['Actual','Predicted'])\n",
    "    plt.savefig('data/risk/' +str(i)+'.png')\n",
    "    plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748b9a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#WHEN USING THIS FOR BASE MODEL, COMMENT OUT EVERYTHING EXCEPT covscale, AND covid_counts.\n",
    "\n",
    "#Split dataset\n",
    "covscale = dataset['covid_counts'].astype('float64')\n",
    "covid_counts = dataset['covid_counts'].astype('float64')\n",
    "isolation_beds = dataset['isolation_beds'].astype('float64')\n",
    "susceptible = dataset['susceptible_counts'].astype('float64')\n",
    "recovery = dataset['recovery_counts'].astype('float64')\n",
    "death = dataset['death_counts'].astype('float64')\n",
    "incidence_rate = dataset['incidence_rate'].astype('float64')\n",
    "quarantine_type_int = dataset['quarantine_type_int'].astype('float64')\n",
    "retail_rec = dataset['retail_rec_baseline'].astype('float64')\n",
    "grocery_pharma = dataset['grocery_pharma_baseline'].astype('float64')\n",
    "parks = dataset['parks_baseline'].astype('float64')\n",
    "transit = dataset['transit_baseline'].astype('float64')\n",
    "workplace = dataset['workplace_baseline'].astype('float64')\n",
    "residential = dataset['residential_baseline'].astype('float64')\n",
    "\n",
    "#Get values of each item of data.\n",
    "covscale = covscale.values\n",
    "covid_counts = covid_counts.values\n",
    "susceptible = susceptible.values\n",
    "recovery = recovery.values\n",
    "death = death.values\n",
    "incidence_rate = incidence_rate.values\n",
    "quarantine_type_int = quarantine_type_int.values\n",
    "retail_rec = retail_rec.values\n",
    "grocery_pharma = grocery_pharma.values\n",
    "parks = parks.values\n",
    "transit = transit.values\n",
    "workplace = workplace.values\n",
    "residential = residential.values\n",
    "isolation_beds = isolation_beds.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcdaafae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape all features.\n",
    "covscale = reshape(covscale)\n",
    "covid_counts = reshape(covid_counts)\n",
    "susceptible = reshape(susceptible)\n",
    "recovery = reshape(recovery)\n",
    "death = reshape(death)\n",
    "incidence_rate = reshape(incidence_rate)\n",
    "quarantine_type_int = reshape(quarantine_type_int)\n",
    "retail_rec = reshape(retail_rec)\n",
    "grocery_pharma = reshape(grocery_pharma)\n",
    "parks = reshape(parks)\n",
    "transit = reshape(transit)\n",
    "workplace = reshape(workplace)\n",
    "residential = reshape(residential)\n",
    "isolation_beds = reshape(isolation_beds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b79c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalize\n",
    "covid_counts = scale(covid_counts)\n",
    "susceptible = scale(susceptible)\n",
    "recovery = scale(recovery)\n",
    "death = scale(death)\n",
    "incidence_rate = scale(incidence_rate)\n",
    "quarantine_type_int = scale(quarantine_type_int)\n",
    "retail_rec = scale(retail_rec)\n",
    "grocery_pharma = scale(grocery_pharma)\n",
    "parks = scale(parks)\n",
    "transit = scale(transit)\n",
    "workplace = scale(workplace)\n",
    "residential = scale(residential)\n",
    "isolation_beds = scale(isolation_beds)\n",
    "\n",
    "#prep inverse scaler\n",
    "scaler = MinMaxScaler(feature_range = (0,1))\n",
    "scaler.fit(covscale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd4e04a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stack columns horizontally\n",
    "#use basedata if running base model.\n",
    "#basedata = np.expand_dims(dataset_stacked, 1)\n",
    "dataset_stackedcov = hstack((covid_counts, susceptible, recovery, death, incidence_rate, quarantine_type_int, retail_rec, grocery_pharma, parks, transit, workplace, residential, isolation_beds, covid_counts))\n",
    "dataset_stacked = hstack((covid_counts, susceptible, recovery, death, incidence_rate, quarantine_type_int, retail_rec, grocery_pharma, parks, transit, workplace, residential, isolation_beds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1c7448",
   "metadata": {},
   "outputs": [],
   "source": [
    "lookback, predict = 60, 60\n",
    "\n",
    "y = split_y(covid_counts, lookback, predict)\n",
    "X, throw = split_sequences(dataset_stackedcov, lookback, predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a18c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X = dataset_stacked[:-1,:], dataset_stacked[-1:,:]\n",
    "train_y, test_y = y[:-1,:], y[-1:,:]\n",
    "print(\"trx:\",train_X.shape, \"tsx:\",test_X.shape,\"try:\",train_y.shape,\"tsy:\", test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b686ad1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#546 used here, because that is index of September 14, 2021. End of the training and start of testing.\n",
    "\n",
    "seeds = rand.sample(range(100000),10)\n",
    "RMSE = {}\n",
    "MAE = {}\n",
    "MAPE = {}\n",
    "for i in seeds:\n",
    "    try:\n",
    "        clf = akTSFModel(i, lookback)\n",
    "        clf.fit(x=train_X[:546,:], y=train_y[:546], batch_size = lookback, epochs=10)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    model = clf.export_model()\n",
    "    try:\n",
    "        model.save(\"final models/autokeras_risk\" + str(i), save_format=\"tf\")\n",
    "    except Exception:\n",
    "        model.save(\"final models/autokeras_risk\" + str(i) + \".h5\")\n",
    "\n",
    "    #prediction on last data value\n",
    "    X_test2 = (X[546:547,:])\n",
    "    predictions = model.predict(X_test2)\n",
    "    #inverse scaling\n",
    "    unscaled_predictions = scaler.inverse_transform(predictions)\n",
    "    unscaled_predictions = unscaled_predictions[0]\n",
    "\n",
    "    RMSE[str(i)] = [str(mean_squared_error(actual['covid_counts'][546:(546+predict)], unscaled_predictions, squared = False))]  \n",
    "    MAE[str(i)] = [str(mean_absolute_error(actual['covid_counts'][546:(546+predict)], unscaled_predictions))]\n",
    "    MAPE[str(i)] = [str(mean_absolute_percentage_error(actual['covid_counts'][546:(546+predict)], unscaled_predictions))]\n",
    "\n",
    "    #plotting\n",
    "    to_plot = actual['covid_counts'][546:(546+predict)]\n",
    "    to_plot = to_plot.reset_index(drop = True)\n",
    "    plot(unscaled_predictions, to_plot, i)\n",
    "\n",
    "    #metrics into dataframe to csv\n",
    "    metricsRMSE = pd.DataFrame(RMSE)\n",
    "    metricsMAE = pd.DataFrame(MAE)\n",
    "    metricsMAPE = pd.DataFrame(MAPE)\n",
    "\n",
    "    metricsRMSE.to_csv('data/risk/Risk RMSEs.csv')\n",
    "    metricsMAE.to_csv('data/risk/Risk MAEs.csv')\n",
    "    metricsMAPE.to_csv('data/risk/Risk MAPEs.csv')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
